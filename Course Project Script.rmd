---
title: 'Predict quality of Exercise: Course Project'
author: "Gaurav Jha"
date: "26 August 2017"
output: html_document
---

#Introduction

The world today is running towards digitalization at a very fast pace, and so does the people. Apart from running, the people also do a lot more to stay healthy, and ironically, there are quantitaive measurements for how much they have done,over a period of time. Along with that, there are gadgets, like $Jawbone Up, Nike FuelBand, and Fitbit$, which tell us the qualitative aspect of the exercises, i.e. how effective or ineffective the exercise was.

This project report is to evaluate, given a set of exercises classified as good or bad, whether the data provided for a new exercise was good or bad.

#Getting the data

```{r}

library(caret)
library(ggplot2)
library(randomForest)
library(corrplot)
library(rpart)
library(plyr)

set.seed(1000)
```

$Ref:$ http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

The training and test data is available at the following links.

training: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

test: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

```{r, cache=TRUE}

#Step 1: Get the data

mainDir <- getwd()
subDir <- "outputDirectory"

if (!file.exists(subDir)){
        dir.create(file.path(mainDir, subDir))
}

if(!file.exists("outputDirectory/training.csv")){
        fileURL_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
        download.file(fileURL_train, destfile = "outputDirectory/training.csv")
        
}

if(!file.exists("outputDirectory/test.csv")){
        fileURL_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
        download.file(fileURL_test, destfile = "outputDirectory/test.csv")
        
}

df_train <- read.csv("outputDirectory/training.csv", stringsAsFactors = FALSE)
df_test <- read.csv("outputDirectory/test.csv", stringsAsFactors = FALSE)

dim(df_train)
```

The training data has 19622 observations while the test data has 20 observations, each of them having 160 features. The 'classe' of exercise is categorized as {'A', 'B', 'C', 'D', 'E'}, where only 'A' is the effective one while others are not.

####Cleaning the data

Since many of the features have 'NA' values, they will be dropped. This is because replacing them with any value will increase the bias in the dataset. Alongside these features, any features that satisfy the following conditions will also be dropped, as they will not be helpful for any model building.

1. Features that are unique for every observation.

2. Features which have SPACES for most of the observations. (These will be considered as NA's)

All these changes will be done in the training dataset only.

```{r}

df_train <- df_train[, -c(1, 3:7)]
df_train$user_name <- as.factor(df_train$user_name)
df_train$classe <- as.factor(df_train$classe)

#Create training and test datasets from the training datasets.

for(i in 1:ncol(df_train)){
        
        if(class(df_train[,i]) == "character"){
                
                df_train[,i] <- as.numeric(df_train[,i])
        }
}

num_na <- sapply(1:ncol(df_train), function(x) sum(is.na(df_train[,x])))

df_train_new <- df_train[, num_na == 0]


```

####Data Split

Once the data is cleansed using the above steps, the training data is partitined into training and test datasets. 75% of the values are kept as training and 25% are kept as test dataset.

```{r}
inTrain <- createDataPartition(y = df_train_new$classe, p = 0.75, list = FALSE)

tempTrain <- df_train_new[inTrain,]
tempTest <- df_train_new[-inTrain,]

table(tempTrain$classe)
```

####Model Selection

Now we are ready to build the model.

This is a classification problem, hence the following algorithms can be used. (Logistic Regression cannot be used because it is used only for two class outcomes where we have 5 in our problem)

1. Decision tree

2. Gradient Boosting Model

```{r}
model1 <- train(classe ~., data = tempTrain, method = "rpart", trControl = trainControl(method = "cv"))

model3 <- train(classe ~., data = tempTrain, method = "gbm", verbose = FALSE, trControl = trainControl(method = "cv"))

print(model1)
print(model3)
```

####Model Descriptions and Inferences.

The preprocessing of the data is done using the cross-validation technique, as a part of the trainControl function.

The accuracy with 'Decision tree' is 47.63% and with GBM is ~96.2%. This gives an out-of-sample error of 52.37 and 3.8% respectively.



