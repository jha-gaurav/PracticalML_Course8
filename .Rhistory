head(routes)
library(plyr)
departures <- ddply(routes, .(sourceAirportID), "nrow")
names(departures)[2] <- "flights"
arrivals <- ddply(routes, .(destinationAirportID), "nrow")
names(arrivals)[2] <- "flights"
airportD <- merge(airports, departures, by.x = "ID", by.y = "sourceAirportID")
airportA <- merge(airports, arrivals, by.x = "ID", by.y = "destinationAirportID")
library(ggmap)
map <- get_map(location = 'Europe', zoom = 4)
mapPoints <- ggmap(map) +
geom_point(aes(x = lon, y = lat, size = sqrt(flights)), data = airportD, alpha = .5)
mapPointsLegend <- mapPoints +
scale_area(breaks = sqrt(c(1, 5, 10, 50, 100, 500)), labels = c(1, 5, 10, 50, 100, 500), name = "departing routes")
mapPointsLegend
# create the data set containing both departures and arrivals
airportD$type <- "departures"
airportA$type <- "arrivals"
airportDA <- rbind(airportD, airportA)
# map the data
# map + data points
mapPointsDA <- ggmap(map) +
geom_point(aes(x = lon, y = lat, size = sqrt(flights)), data = airportDA, alpha = .5)
# adjust the legend
mapPointsLegendDA <- mapPointsDA +
scale_area(breaks = sqrt(c(1, 5, 10, 50, 100, 500)), labels = c(1, 5, 10, 50, 100, 500), name = "routes")
# panels according to type (departure/arrival)
mapPointsFacetsDA <- mapPointsLegendDA +
facet_grid(. ~ type)
# plot the map
mapPointsFacetsDA
install.packages("plotly")
library(plotly)
df <- read.csv('https://raw.githubusercontent.com/plotly/datasets/master/2011_february_us_airport_traffic.csv')
g <- list(
scope = 'usa',
projection = list(type = 'albers usa'),
showland = TRUE,
landcolor = toRGB("gray95"),
subunitcolor = toRGB("gray85"),
countrycolor = toRGB("gray85"),
countrywidth = 0.5,
subunitwidth = 0.5
)
p <- plot_geo(df, lat = ~lat, lon = ~long) %>%
add_markers(
text = ~paste(airport, city, state, paste("Arrivals:", cnt), sep = "<br />"),
color = ~cnt, symbol = I("square"), size = I(8), hoverinfo = "text"
) %>%
colorbar(title = "Incoming flights<br />February 2011") %>%
layout(
title = 'Most trafficked US airports<br />(Hover for airport)', geo = g
)
chart_link = plotly_POST(p, filename="maps/traffic")
chart_link
chart_link = plotly_POST(p, filename="maps/traffic")
q()
library("SentimentAnalysis", lib.loc="~/R/win-library/3.4")
detach("package:SentimentAnalysis", unload=TRUE)
library(datasets)
data(crime)
library(ggmap)
data(crime)
str(crime)
qmap('houston', zoom = 13)
gglocator(2)
gglocator(1)
violent_crimes <- subset(crime,
+ offense != "auto theft" & offense != "theft" & offense != "burglary")
violent_crimes <- subset(crime,
offense != "auto theft" & offense != "theft" & offense != "burglary")
violent_crimes$offense <- factor(violent_crimes$offense,
levels = c("robbery", "aggravated assault", "rape", "murder"))
violent_crimes <- subset(violent_crimes,
-95.39681 <= lon & lon <= -95.34188 &
29.73631 <= lat & lat <= 29.78400)
theme_set(theme_bw(16))
HoustonMap <- qmap("houston", zoom = 14, color = "bw", legend = "topleft")
HoustonMap +
geom_point(aes(x = lon, y = lat, colour = offense, size = offense),
data = violent_crimes)
HoustonMap +
stat_bin2d(
aes(x = lon, y = lat, colour = offense, fill = offense),
size = .5, bins = 30, alpha = 1/2,
data = violent_crimes
)
install.packages("googleVis")
cities <- c("ARNHEM","ATHENS","BAAR","CAMBRIDGESHIRE")
library(ggmap)
geocode(cities[1])
cities <- c("NEW DELHI","ATHENS","BAAR","CAMBRIDGESHIRE")
geocode(cities[1])
cities <- c("GURGAON","ATHENS","BAAR","CAMBRIDGESHIRE")
geocode(cities[1])
cities <- c("COCHIN","ATHENS","BAAR","CAMBRIDGESHIRE")
geocode(cities[1])
q()
text <- c("Because I could not stop for Death -",
"He kindly stopped for me -",
"The Carriage held but just Ourselves -",
"and Immortality")
text
library(dplyr)
text_df <- data_frame(line = 1:4, text = text)
text_df
library(tidytext)
text_df %>%
unnest_tokens(word, text)
###############################
library(janeaustenr)
library(dplyr)
library(stringr)
original_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup()
original_books
tidy_books <- original_books %>%
unnest_tokens(word, text)
tidy_books
data(stop_words)
tidy_books <- tidy_books %>%
anti_join(stop_words)
tidy_books
tidy_books %>%
count(word, sort = TRUE)
library(ggplot2)
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
library(gutenbergr)
hgwells <- gutenberg_download(c(35, 36, 5230, 159))
tidy_hgwells <- hgwells %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_hgwells %>%
count(word, sort = TRUE)
bronte <- gutenberg_download(c(1260, 768, 969, 9182, 767))
tidy_bronte <- bronte %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
tidy_bronte %>%
count(word, sort = TRUE)
library(tidyr)
frequency <- bind_rows(mutate(tidy_bronte, author = "Brontë Sisters"),
mutate(tidy_hgwells, author = "H.G. Wells"),
mutate(tidy_books, author = "Jane Austen")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(author, proportion) %>%
gather(author, proportion, `Brontë Sisters`:`H.G. Wells`)
frequency
library(scales)
ggplot(frequency, aes(x = proportion, y = `Jane Austen`, color = abs(`Jane Austen` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
facet_wrap(~author, ncol = 2) +
theme(legend.position="none") +
labs(y = "Jane Austen", x = NULL)
library(tidytext)
sentiments
get_sentiments(loughran)
get_sentiments("loughran")
get_sentiments("afinn")
get_sentiments("nrc")
class(get_sentiments("nrc"))
nrc_df <- get_sentiments("nrc")
str(nrc_df)
unique(nrc_df$sentiment)
nrc_df[nrc_df$sentiment == "anticipation"]
nrc_df[nrc_df$sentiment == "anticipation",]
nrc_df[nrc_df$sentiment == "trust",]
nrc_df[nrc_df$sentiment == "positive",]
get_sentiments("loughran")
lgh_df <- get_sentiments("loughran")
unique(lgh_df$sentiment)
lgh_df[lgh_df$sentiment == "litigious",]
get_sentiments("afinn")
library(janeaustenr)
library(dplyr)
library(stringr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books
nrcjoy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrcjoy) %>%
count(word, sort = TRUE)
5/3
5%/%3
floor(5/3)
?spread
library(tidyr)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
janeaustensentiment
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment)
janeaustensentiment
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
library(ggplot2)
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
str(nrc_df)
nrc_df[nrc_df$word == "suggest",]
unique(nrc_df$sentiment)
nrc_df[nrc_df$sentiment == "trust",]
install.packages(c("wordcloud", "reshape2", "wordcloud2"))
q()
devtools::install_github("rstudio/rmarkdown")
install.packages("devtools")
devtools::install_github("rstudio/rmarkdown")
rmarkdown::render('in.md',
output_format=pdf_document(latex_engine='xelatex')
)
# List of useful packages
pkg <- c("tidyr", "dplyr", "ggplot2", "knitr", "rmarkdown")
# Check if packages are not installed and assign the
# names of the uninstalled packages to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg)) {
install.packages(new.pkg, repos = "http://cran.rstudio.com")
}
cars <- data(mtcars)
str(cars)
data(mtcars)
str(mtcars)
?mtcars
q()
q()
q()
library(dplyr)
mtcars_sub <- select(mtcars, mpg, am)
fit <- lm(mpg ~ am, data = mtcars_sub)
coef(fit)
q()
install.packages("caret")
q()
q()
download.datasets("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
??download.datasets
??download.dataset
??download.data
str(df_train)
fileURL_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL_train, destfile = "training.csv")
df_train <- read.csv("training.csv", stringsAsFactors = FALSE)
fileURL_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL_test, destfile = "test.csv")
df_test <- read.csv("test.csv", stringsAsFactors = FALSE)
dim(df_train)
dim(df_test)
table(df_train$classe)
str(df_train)
table(df_train$user_name)
for (i in 1:160){
table(df_train[,i])
}
table(df_train[,1])
table(df_train$new_window)
q()
install.packages("kernlab")
library(kernlab)
data(spam)
head(spam)
plot(density(spam$your[spam$type == "nonspam"]),
col="blue", main = "", xlab = "Frequency of 'your'")
prediction <- ifelse(spam$your > 0.5, "spam", "nonspam")
table(prediction, spam$type) / length(spam$type)
q()
setwd("F:/Coursera/Course8/Course Project")
setwd("F:/Coursera/Course8/Course Project")
library(caret)
library(ggplot2)
library(randomForest)
library(corrplot)
set.seed(1000)
#Step 1: Get the data
mainDir <- getwd()
subDir <- "outputDirectory"
if (!file.exists(subDir)){
dir.create(file.path(mainDir, subDir))
}
if(!file.exists("outputDirectory/training.csv")){
fileURL_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL_train, destfile = "outputDirectory/training.csv")
}
if(!file.exists("outputDirectory/test.csv")){
fileURL_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL_test, destfile = "outputDirectory/test.csv")
}
df_train <- read.csv("outputDirectory/training.csv", stringsAsFactors = FALSE)
df_test <- read.csv("outputDirectory/test.csv", stringsAsFactors = FALSE)
#Create training and test datasets from the training datasets.
inTrain <- createDataPartition(y = df_train$classe, p = 0.75, list = FALSE)
tempTrain <- df_train[inTrain,]
tempTest <- df_train[-inTrain,]
#Create a new dataframe with user name and classe variables.
#The other features will be added subsequently to this dataframe
new.train <- cbind(tempTrain$user_name, tempTrain$classe)
new.test <- cbind(tempTest$user_name, tempTest$classe)
new.final.test <- df_test$user_name
colnames(new.train) <- colnames(new.test) <- c("user_name", "classe")
#The input data contains data from four categories, i.e. belt, arm, forearm and dumbbell.
#We will analyse each class one by one.
temp_belt_df <- tempTrain[,grep("belt", colnames(tempTrain))]
temp_arm_df <- tempTrain[,grep("_arm", colnames(tempTrain))]
temp_forearm_df <- tempTrain[,grep("forearm", colnames(tempTrain))]
temp_dumbbell_df <- tempTrain[,grep("dumbbell", colnames(tempTrain))]
temp_belt_df.test <- tempTest[,grep("belt", colnames(tempTest))]
temp_arm_df.test <- tempTest[,grep("_arm", colnames(tempTest))]
temp_forearm_df.test <- tempTest[,grep("forearm", colnames(tempTest))]
temp_dumbbell_df.test <- tempTest[,grep("dumbbell", colnames(tempTest))]
str(temp_belt_df)
belt_df.test <- df_test[,grep("belt", colnames(df_test))]
arm_df.test <- df_test[,grep("_arm", colnames(df_test))]
forearm_df.test <- df_test[,grep("forearm", colnames(df_test))]
dumbbell_df.test <- df_test[,grep("dumbbell", colnames(df_test))]
#Let's analyse the belt data first
str(temp_belt_df)
sapply(1:ncol(temp_belt_df), function(x) sum(is.na(df_train[,x])))
#The fields kurtosis, skewness, max_yaw, min_yaw and amplitude_yaw are characters
#and have lot of missing values. We will convert these fields to numeric as they contain numbers.
for(i in 1:ncol(temp_belt_df)){
if(class(temp_belt_df[,i]) == "character"){
temp_belt_df[,i] <- as.numeric(temp_belt_df[,i])
temp_belt_df.test[,i] <- as.numeric(temp_belt_df.test[,i])
belt_df.test[,i] <- as.numeric(belt_df.test[,i])
}
if(class(temp_arm_df[,i]) == "character"){
temp_arm_df[,i] <- as.numeric(temp_arm_df[,i])
temp_arm_df.test[,i] <- as.numeric(temp_arm_df.test[,i])
arm_df.test[,i] <- as.numeric(arm_df.test[,i])
}
if(class(temp_forearm_df[,i]) == "character"){
temp_forearm_df[,i] <- as.numeric(temp_forearm_df[,i])
temp_forearm_df.test[,i] <- as.numeric(temp_forearm_df.test[,i])
forearm_df.test[,i] <- as.numeric(forearm_df.test[,i])
}
if(class(temp_dumbbell_df[,i]) == "character"){
temp_dumbbell_df[,i] <- as.numeric(temp_dumbbell_df[,i])
temp_dumbbell_df.test[,i] <- as.numeric(temp_dumbbell_df.test[,i])
dumbbell_df.test[,i] <- as.numeric(dumbbell_df.test[,i])
}
}
#Calculate mean of all columns
for(i in 1:ncol(temp_belt_df)){
m1 <- mean(temp_belt_df[,i], na.rm = TRUE)
temp_belt_df[is.na(temp_belt_df[,i]), i] <- m1
temp_belt_df.test[is.na(temp_belt_df.test[,i]), i] <- m1
belt_df.test[is.na(belt_df.test[,i]), i] <- m1
m1 <- mean(temp_arm_df[,i], na.rm = TRUE)
temp_arm_df[is.na(temp_arm_df[,i]), i] <- m1
temp_arm_df.test[is.na(temp_arm_df.test[,i]), i] <- m1
arm_df.test[is.na(arm_df.test[,i]), i] <- m1
m1 <- mean(temp_forearm_df[,i], na.rm = TRUE)
temp_forearm_df[is.na(temp_forearm_df[,i]), i] <- m1
temp_forearm_df.test[is.na(temp_forearm_df.test[,i]), i] <- m1
forearm_df.test[is.na(forearm_df.test[,i]), i] <- m1
m1 <- mean(temp_dumbbell_df[,i], na.rm = TRUE)
temp_dumbbell_df[is.na(temp_dumbbell_df[,i]), i] <- m1
temp_dumbbell_df.test[is.na(temp_dumbbell_df.test[,i]), i] <- m1
dumbbell_df.test[is.na(dumbbell_df.test[,i]), i] <- m1
}
str(temp_belt_df)
#The fields kurtosis_yaw_belt and skewness_yaw_belt have NaN values. Will drop them.
temp_belt_df$kurtosis_yaw_belt <- NULL
temp_belt_df$skewness_yaw_belt <- NULL
str(temp_arm_df)
#All features for arm are good.
str(temp_forearm_df)
#The fields kurtosis_yaw_forearm and skewness_yaw_forearm have NaN values. Will drop them.
temp_forearm_df$kurtosis_yaw_forearm <- NULL
temp_forearm_df$skewness_yaw_forearm <- NULL
str(temp_dumbbell_df)
#The fields kurtosis_yaw_dumbbell and skewness_yaw_dumbbell have NaN values. Will drop them.
temp_dumbbell_df$kurtosis_yaw_dumbbell <- NULL
temp_dumbbell_df$skewness_yaw_dumbbell <- NULL
#Create a cleat training dataset
final_train <- cbind(new.train, temp_belt_df, temp_arm_df, temp_forearm_df, temp_dumbbell_df)
final_test <- cbind(new.test, temp_belt_df.test, temp_arm_df.test, temp_forearm_df.test, temp_dumbbell_df.test)
str(final_train)
#Create a model
model1 <- train(classe ~., data = final_train, method = "rpart")
model2 <- train(classe ~., data = final_train, method = "rf")
library(caret)
library(ggplot2)
library(randomForest)
library(corrplot)
library(rpart)
set.seed(1000)
#Step 1: Get the data
mainDir <- getwd()
subDir <- "outputDirectory"
if (!file.exists(subDir)){
dir.create(file.path(mainDir, subDir))
}
if(!file.exists("outputDirectory/training.csv")){
fileURL_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL_train, destfile = "outputDirectory/training.csv")
}
if(!file.exists("outputDirectory/test.csv")){
fileURL_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL_test, destfile = "outputDirectory/test.csv")
}
df_train <- read.csv("outputDirectory/training.csv", stringsAsFactors = FALSE)
df_test <- read.csv("outputDirectory/test.csv", stringsAsFactors = FALSE)
num_na <- sapply(1:ncol(df_train), function(x) sum(is.na(df_train[,x])))
num_na
df_train_new <- df_train[, num_na == 0]
str(df_train_new)
df_train <- df_train[, -c(1, 3:7)]
str(df_train)
df_train$user_name <- as.factor(df_train$user_name)
df_train$classe <- as.factor(df_train$classe)
num_na <- sapply(1:ncol(df_train), function(x) sum(is.na(df_train[,x])))
df_train_new <- df_train[, num_na == 0]
str(df_train_new)
for(i in 1:ncol(df_train_new)){
if(class(df_train_new[,i]) == "character"){
df_train_new[,i] <- NULL
}
}
library(caret)
library(ggplot2)
library(randomForest)
library(corrplot)
library(rpart)
set.seed(1000)
#Step 1: Get the data
mainDir <- getwd()
subDir <- "outputDirectory"
if (!file.exists(subDir)){
dir.create(file.path(mainDir, subDir))
}
if(!file.exists("outputDirectory/training.csv")){
fileURL_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL_train, destfile = "outputDirectory/training.csv")
}
if(!file.exists("outputDirectory/test.csv")){
fileURL_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL_test, destfile = "outputDirectory/test.csv")
}
df_train <- read.csv("outputDirectory/training.csv", stringsAsFactors = FALSE)
df_test <- read.csv("outputDirectory/test.csv", stringsAsFactors = FALSE)
df_train <- df_train[, -c(1, 3:7)]
df_train$user_name <- as.factor(df_train$user_name)
df_train$classe <- as.factor(df_train$classe)
str(df_train)
for(i in 1:ncol(df_train_new)){
if(class(df_train_new[,i]) == "character"){
df_train_new[,i] <- as.numeric(df_train_new[,i])
}
}
for(i in 1:ncol(df_train)){
if(class(df_train[,i]) == "character"){
df_train[,i] <- as.numeric(df_train[,i])
}
}
num_na <- sapply(1:ncol(df_train), function(x) sum(is.na(df_train[,x])))
num_na
df_train_new <- df_train[, num_na == 0]
str(df_train_new)
inTrain <- createDataPartition(y = df_train$classe, p = 0.75, list = FALSE)
tempTrain <- df_train[inTrain,]
tempTest <- df_train[-inTrain,]
tempTrain <- df_train_new[inTrain,]
tempTest <- df_train_new[-inTrain,]
inTrain <- createDataPartition(y = df_train_new$classe, p = 0.75, list = FALSE)
tempTrain <- df_train_new[inTrain,]
tempTest <- df_train_new[-inTrain,]
table(tempTrain$classe)
model1 <- train(classe ~., data = tempTrain, method = "rpart")
model2 <- train(classe ~., data = tempTrain, method = "rf")
model3 <- train(classe ~., data = tempTrain, method = "gbm", verbose = FALSE)
confusionMatrix(predict(model3, newdata = tempTest), tempTest$classe)
predict(model3, newdata = test_df)
predict(model3, newdata = df_test)
q()
